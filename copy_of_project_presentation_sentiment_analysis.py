# -*- coding: utf-8 -*-
"""Copy of Project Presentation Sentiment Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JDUh6d2KgXCg5j6gYhNQzKVCSiBE2oIf

## Sentiment Analysis Task
In this task, one will create a classification model that will be able to receive a sentence and give the sentiment of the sentence.

    * We will use this dataset: https://huggingface.co/datasets/sentiment140 for training and evaluation

    * We will use tweets from lesson 1 for inference
    
    * The model will be deployed. Follow the fine tuning process that we used during the class exercises when using LM

    * You will first use traditional ML then use Language models and compare the results
"""

from google.colab import drive
drive.mount('/content/drive')

# We have a class called Ml Model
path_other_datasets = "/content/drive/MyDrive/Colab Notebooks/nlp_training_ff_giz/projects/trainingandtestdata.zip"

!unzip "/content/drive/MyDrive/Colab Notebook/nlp_training_ff_giz/projects/trainingandtestdata.zip"

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import wordpunct_tokenize
from nltk.stem import PorterStemmer
from wordcloud import WordCloud
import re
import gensim
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
from sklearn.utils import resample
from sklearn.metrics import accuracy_score,f1_score, confusion_matrix

"""#***I. TODO LOAD THE DATASET***"""

train= pd.read_csv("/content/training.1600000.processed.noemoticon.csv",names=['polarity', 'id', 'date', 'query', 'user', 'text'],encoding='latin-1')
train.head()

train.info()

print('shape of train dataset',train.shape)
train.polarity.value_counts()

"""#***II. TODO PREPOCESS AND EXPLORE THE DATA***"""

train1= train.drop(['id', 'date', 'query', 'user'], axis = 1)
#df = df.drop(columns=['id', 'date', 'query', 'user'])
train1.head()

# 1=Positive tweet and 0=Negative tweet
train1.polarity = train1.polarity.replace({0: 0, 4: 1})
train1.polarity.value_counts()

data_positive=train1[train1['polarity']>=1][:10000]
data_negative=train1[train1['polarity']<1][:10000]
data=pd.concat([data_positive,data_negative])

data.polarity.value_counts()

data.head()

# clean text to remove users, links and stopwords and then split it in tokens
def clean_text(text):
    text_cleaning_re = "@\S+|https?:\S+|http?:\S|[^A-Za-z0-9]+"
    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()
    
    tokens = text.split()
    stop_words = set(stopwords.words('english'))
    tokens = [w for w in tokens if w not in stop_words]
    
    return " ".join(tokens)

import nltk
nltk.download('stopwords')
# apply clean_text function in our data
data.text = data.text.apply(lambda x: clean_text(x))
# show the first five rows of data (to verify again)
data.sample(4)

df=data[['text','polarity']]
df.tail()

print('Number of all texts:', len(df), '\n')
print('Number of positive texts:', len(df[df.polarity == 1]))
print('Number of negative texts:', len(df[df.polarity == 0]), '\n')

sns.countplot(df.polarity,)
plt.xlabel('class polarity')
plt.ylabel('number of tweets')
plt.show()

plt.hist(df[df['polarity']==1].text.str.len(),bins=20,label='class 1')
plt.legend()
plt.xlabel('length of texts')
plt.ylabel('number of texts')
plt.show()
plt.hist(df[df['polarity']==0].text.str.len(),color='yellow',bins=20,label='class 0')
plt.legend()
plt.xlabel('length of texts')
plt.ylabel('number of texts')
plt.show()

"""#***Splitting our train dataset into X_train and y_train***"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split

df.head()

val=df.iloc[7852]
val['text']

# Splitting Train Test Data
X, y = df['text'].astype('str'), df['polarity']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# Text vectorizing and Save the model into Joblib
import joblib
cv = CountVectorizer()
X_train_vec = cv.fit_transform(X_train)
joblib.dump(cv,'countvector.pkl')
X_test_vec= cv.transform(X_test)

# class to be reused for traditional ML

from sklearn import svm
from sklearn import linear_model
from sklearn import neighbors
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
import joblib
from sklearn.metrics import classification_report
import json

class MLModel:
  def __init__(self, target_model, save_path):
    self.save_path = save_path
    self.models = {"ols":linear_model.LinearRegression(), # regression
            "svm":svm.SVC(),
            "ridge":linear_model.Ridge(alpha=.5), # regression
            "lasso":linear_model.Lasso(alpha=0.1), # regression
            "knn":neighbors.KNeighborsClassifier(5), 
            "logistic":linear_model.LogisticRegression(),
            "nb":MultinomialNB(),
            "randomforest":RandomForestClassifier(n_estimators=10),
            "sgd_svm":linear_model.SGDClassifier(max_iter=1000, tol=1e-3)} # you can add more models as pleased
    
    if target_model is not None:
      if target_model in self.models.keys():
        self.model = self.models[target_model]
      else:
        raise NotImplementedError
    
    self.clf = None
  
  def fit(self, X, y, max_iter=None):
    #put your code down here
    self.clf = self.model.fit(X, y, max_iter=max_iter) if max_iter else self.model.fit(X, y)

  def save(self, mode="pickle"):
    if mode == "pickle":
      if self.clf is not None:
        joblib.dump(self.clf, self.save_path)
      else:
        raise ValueError("train before saving the classifier")

    elif mode == "json":
      if self.clf is not None:
        model_dict = {}
        model_dict["clf"] = self.clf
        json_clf = json.dumps(model_dict, indent=4)
        with open(self.save_path+"/model.json", 'w') as file:
            file.write(json_clf)
        file.close()
      else:
        raise ValueError("Train before saving the classifier")
    else:
      raise NotImplementedError

  def load(self, path, mode):
    if mode == "pickle":
      self.clf = joblib.load(path)
      print(self.clf)
    elif mode == "json":
      with open(path, 'r') as file:
          model_dict = json.load(file)
      self.clf = model_dict["clf"]
    else:
      raise NotImplementedError
    return self.clf

  def predict(self, X):
    predictions = self.clf.predict(X)
    return predictions

  def evaluate(self, y_true, y_pred, target_names):
    # put your code down here add eval
    print(classification_report(y_true, y_pred, target_names=target_names))

"""from sklearn import linear_model
clf=linear_model.LogisticRegression(max_iter=1000)
clf.fit(X_train_vec,y_train)
pred=clf.predict(X_test_vec)

print('accuracy:',sum(pred==y_test)*1.0/len(y_test))"""

# calling the ML calss For Logistic Regression
model_logistic = MLModel("logistic", "./logistic.pkl")
model_logistic.fit(X=X_train_vec, y=y_train)
Logistic_pred = model_logistic.predict(X_test_vec)
print("accuracy: ", sum(Logistic_pred==y_test)*1.0/len(y_test))

print("Full classification evaluation report:")
model_logistic.evaluate(Logistic_pred, y_test, target_names=[str(i) for i in np.unique(y_test)])

Logistic_pred





cm = confusion_matrix(y_test,Logistic_pred)
cm
# after creating the confusion matrix, for better understaning plot the cm.
import seaborn as sn
plt.figure(figsize = (4,3))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')

# save model for reuse LOGISTIC REGRESSION
model_logistic.save()

loaded_logistic_model = model_logistic.load('./logistic.pkl',  mode="pickle")
Logistic_predict = loaded_logistic_model.predict(X_test_vec)
print(Logistic_predict)
sum(Logistic_predict==y_test)*1.0/len(y_test)
model_logistic.evaluate(Logistic_predict, y_test, target_names=[str(i) for i in np.unique(y_test)])

# calling the ML calss For MULTINOMIAL NAIVE BAYES
model_nb = MLModel("nb", "./nb.pkl")
model_nb.fit(X=X_train_vec, y=y_train)
NB_pred = model_nb.predict(X_test_vec)
print("accuracy: ", sum(NB_pred==y_test)*1.0/len(y_test))

print("Full classification evaluation report:")
model_nb.evaluate(NB_pred, y_test, target_names=[str(i) for i in np.unique(y_test)])

cm = confusion_matrix(y_test,NB_pred)
cm
# after creating the confusion matrix, for better understaning plot the cm.
import seaborn as sn
plt.figure(figsize = (4,3))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')

# save model for reuse MULTINOMIAL NAIVE BAYES
model_nb.save()

loaded_nb_model = model_nb.load('./nb.pkl',  mode="pickle")
NB_predict = loaded_nb_model.predict(X_test_vec)
print(NB_predict)
sum(NB_predict==y_test)*1.0/len(y_test)
model_nb.evaluate(NB_predict, y_test, target_names=[str(i) for i in np.unique(y_test)])

# calling the ML calss For KNN
model_knn = MLModel("knn", "./knn.pkl")
model_knn.fit(X=X_train_vec, y=y_train)
KNN_pred = model_knn.predict(X_test_vec)
print("accuracy: ", sum(KNN_pred==y_test)*1.0/len(y_test))

print("Full classification evaluation report:")
model_knn.evaluate(KNN_pred, y_test, target_names=[str(i) for i in np.unique(y_test)])

from sklearn import neighbors
clf=neighbors.KNeighborsClassifier(5)
clf.fit(X_train_vec,y_train)
pred=clf.predict(X_test_vec)

print('accuracy:',sum(pred==y_test)*1.0/len(y_test))

cm = confusion_matrix(y_test,KNN_pred)
cm
# after creating the confusion matrix, for better understaning plot the cm.
import seaborn as sn
plt.figure(figsize = (4,3))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')

# save model for reuse KNN
model_knn.save()

loaded_knn_model = model_knn.load('./knn.pkl',  mode="pickle")
KNN_predict = loaded_knn_model.predict(X_test_vec)
print(KNN_predict)
sum(KNN_predict==y_test)*1.0/len(y_test)
model_knn.evaluate(KNN_predict, y_test, target_names=[str(i) for i in np.unique(y_test)])

# calling the ML calss For RANDOM FOREST
model_rf = MLModel("randomforest", "./RF.pkl")
model_rf.fit(X=X_train_vec, y=y_train)
RF_pred = model_rf.predict(X_test_vec)
print("accuracy: ", sum(RF_pred==y_test)*1.0/len(y_test))

print("Full classification evaluation report:")
model_rf.evaluate(RF_pred, y_test, target_names=[str(i) for i in np.unique(y_test)])

cm = confusion_matrix(y_test,RF_pred)
cm
# after creating the confusion matrix, for better understaning plot the cm.
import seaborn as sn
plt.figure(figsize = (4,3))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')

# save model for reuse RANDOM FOREST
model_rf.save()

loaded_rf_model = model_rf.load('./RF.pkl',  mode="pickle")
RF_predict = loaded_rf_model.predict(X_test_vec)
print(RF_predict)
sum(RF_predict==y_test)*1.0/len(y_test)
model_rf.evaluate(RF_predict, y_test, target_names=[str(i) for i in np.unique(y_test)])

# calling the ML calss For SUPPORT VECTOR MACHINE
model_svm = MLModel("svm", "./SVM.pkl")
model_svm.fit(X=X_train_vec, y=y_train)
SVM_pred = model_svm.predict(X_test_vec)
print("accuracy: ", sum(SVM_pred==y_test)*1.0/len(y_test))

print("Full classification evaluation report:")
model_svm.evaluate(SVM_pred, y_test, target_names=[str(i) for i in np.unique(y_test)])

cm = confusion_matrix(y_test,SVM_pred)
cm
# after creating the confusion matrix, for better understaning plot the cm.
import seaborn as sn
plt.figure(figsize = (4,3))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')

# save model for reuse SUPPORT VECTOR MACHINE
model_svm.save()

loaded_svm_model = model_svm.load('./SVM.pkl',  mode="pickle")
SVM_predict = loaded_svm_model.predict(X_test_vec)
print(SVM_predict)
sum(SVM_predict==y_test)*1.0/len(y_test)
model_svm.evaluate(SVM_predict, y_test, target_names=[str(i) for i in np.unique(y_test)])

"""#***SUMMARY***
<table>
<tr>
<td>MODELS</td>

</tr>
<tr><td>    </td>
<td>Accuracy</td>
<td>f1_score</td>

</tr>
<tr><td>  LOGISTIC REGRESSION</td>
<td>0.7222</td>
<td>0.72</td>

<tr><td>  NAIVE BAYES </td>
<td>0.7156</td>
<td>0.72</td>

<tr><td>  K-NEAREST NEIGHBORS </td>
<td>0.6266</td>
<td>0.63</td>

</tr>
<tr><td>  RANDOM FOREST </td>
<td>0.7032</td>
<td>0.70</td>

</tr>
<tr><td>  SUPPORT VECTOR MACHINE </td>
<td>0.7328</td>
<td>0.73</td>

</tr>
</table>

#***III. TODO USE THE DIFFERENT FEATURE ENGINEERING TECHNIQUES - BoW, TD-IDF ADN Word Embeddings***

#1) BOW TECHNIQUE
"""

bow=CountVectorizer( min_df=2, max_features=100)
bow.fit(df['text'])
bow_df=bow.transform(df['text']).toarray()
print('feature name==',bow.get_feature_names()[:10])
print('number of uniqe words',bow_df.shape[1])
print('shape',bow_df.shape)
bow_train=pd.DataFrame(bow_df)
bow_train.head()

"""#2) TF-IDF TECHNIQUE"""

tfidf=TfidfVectorizer(ngram_range=(1, 2),min_df=2,max_features=1000)
tfidf.fit(df['text'])
tfidf_df=tfidf.transform(df['text']).toarray()
print('number of uniqe words',bow_df.shape[1])
print('shape',tfidf_df.shape)
tfidf_train=pd.DataFrame(tfidf_df)
tfidf_train.head()

"""#3) Word2vec TECHNIQUE"""

tokenize=df['text'].apply(lambda x: x.split())
w2vec_model=gensim.models.Word2Vec(tokenize,min_count = 1, size = 100, window = 5, sg = 1)
w2vec_model.train(tokenize,total_examples= len(df['text']),epochs=20)

w2vec_model.most_similar('bed')

w2v_words = list(w2vec_model.wv.vocab)
print("number of words that occured minimum 5 times ",len(w2v_words))
print("sample words ", w2v_words[0:50])

from model import sentiment